from math import log

def calcShannonEnt(dataset)://计算香农熵
    numentries=len(dataset)//计算数据总量（在这里定义是为了节省时间）
    labelcounts={}//字典
    for featvec in dataset:
        currentlabel=featvec[-1]//提取特征点的最后一个信息，就是标签
        if currentlabel not in labelcounts.keys():
            labelcounts[currentlabel]=0
        labelcounts[currentlabel]+=1
    shannonent=0.0
    for key in labelcounts:
        prob=float(labelcounts[key])/numentries//计算概率
        shannonent-=prob*log(prob,2)

    return shannonent

def createDataSet()://创建一个测试数据
    dataset=[[1,1,'yes'],[1,1,'yes'],[1,0,'no'],[0,1,'no'],[0,1,'no']]
    labels=['no surfacing','fippers']
    return dataset,labels

def splitDataSet(dataset,axis,value)://按照某一特征重新划分数据集
    retdataset=[]
    for featvec in dataset:
        if featvec[axis]==value:
            reducedfeatvec=featvec[:axis]
            reducedfeatvec.extend(featvec[axis+1:])
            retdataset.append(reducedfeatvec)
    return retdataset

def chooseBestFeatureToSplit(dataset)：//选择最好的特征进行下一步分类
    numfeatures=len(dataset[0])-1
    bestinfogain=0.0
    bestfeature=-1
    for i in range(numfeatures):
        featlist=[example[i] for example in dataset]
        uniquevals=set(featlist)
        newentropy=0.0
        for value in uniquevals:
            subdataset=splitDataSet(dataset,i,value)
            prob=len(subdataset)/float(len(dataset))
            newentropy+=prob*calcShannonEnt(subdataset)
        infogain=baseentropy-newentropy
        if(infogain>bestinfogain)
            bestinfogain=infogain
            bestfeature=i
    return bestfeature
